<!DOCTYPE html>
<html lang="en">
	<head>
		<title>Conditional Modeling Toolkit Tutorials</title>
		<meta charset="UTF-8">
		<meta name="author" content="Lucas Theis">
		<meta name="description" content="Conditional Modeling Toolkit Tutorials">
		<link rel="stylesheet" href="http://yandex.st/highlightjs/7.3/styles/tomorrow.min.css">
		<link rel="stylesheet" type="text/css" href="style.css">
		<script src="http://yandex.st/highlightjs/7.3/highlight.min.js"></script>
		<script type="text/x-mathjax-config">
			MathJax.Hub.Config({
				tex2jax: {
					inlineMath: [['$','$']],
					displayMath: [['$$','$$']],
					skipTags: ["script","noscript","style","textarea","code"],
					processEnvironments: true
				}
			});
		</script>
		<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
		<script>
			hljs.tabReplace = '    ';
			hljs.initHighlightingOnLoad();
		</script>
	</head>
	<body>
		<article>
			<h1>Probabilistic modeling of color images</h1>
				<h2 id="introduction">Introduction</h2>

				<figure>
					<img src="media/newyork.png" alt="New York">
					<figcaption>&copy; Chris Isherwood, 2008</figcaption>
				</figure>

				In this tutorial, we will add some color to our samples. For this, we will have
				to learn a distribution not only over grayscale images, $\mathbf{I} \in
				\mathbb{R}^{M \times N}$, but over color images, $\mathbf{I} \in \mathbb{R}^{M
				\times N \times 3}$.<br>
				<br>
				 We will split this task into two subproblems by separating the grayscale
				 intensities, $\mathbf{I}_0 \in \mathbb{R}^{M \times N}$, from the color
				 information, $\mathbf{I}_1 \in \mathbb{R}^{M \times N \times 2}$.
				 This can be achieved by mapping the RGB pixel values of an image to a 
				 <a href="http://en.wikipedia.org/wiki/YCbCr">different color space</a> using
				 a simple linear transformation. Instead of learning a distribution over
				 $\mathbf{I}$ directly, we are going to learn a distribution for $\mathbf{I}_0$
				 and a conditional distribution for $\mathbf{I}_1$ given $\mathbf{I}_0$.
				 Together, they define a distribution over color images,
				 \begin{align*}
					 P(\mathbf{I}) \propto P(\mathbf{I}_1 \mid \mathbf{I}_0) P(\mathbf{I}_0).
				 \end{align*}
				 <br>

				<h2 id="fitting">Fitting model parameters</h2>

				Since we are going to fit two models in this tutorial, it makes sense to first encapsulate
				the training procedure.
					
				<pre><code class="python">from cmt.tools import generate_data_from_image
from cmt.models import MCGSM
from cmt.transforms import WhiteningPreconditioner

def train_model(img, input_mask, output_mask):
	# generate data
	inputs, outputs = generate_data_from_image(
		img, input_mask, output_mask, 120000)

	# split data into training and validation sets
	data_train = inputs[:, :100000], outputs[:, :100000]
	data_valid = inputs[:, 100000:], outputs[:, 100000:]

	# compute normalizing transformation
	pre = WhiteningPreconditioner(*data_train)

	# intialize model
	model = MCGSM(
		dim_in=data_train[0].shape[0],
		dim_out=data_train[1].shape[0],
		num_components=8,
		num_scales=4,
		num_features=30)

	# fit parameters
	model.initialize(*pre(*data_train))
	model.train(*chain(pre(*data_train), pre(*data_valid)),
		parameters={
			'verbosity': 1,
			'max_iter': 1000,
			'threshold': 1e-7,
			'val_iter': 5,
			'val_look_ahead': 10,
			'num_grad': 20,
		})

	return model, pre</code></pre>

				If you are unclear about what this function does, take a look at the previous
				<a href="images.html">tutorial on modeling grayscale images</a>.

				Next, we are going to load an RGB image and transform it to a
				<a href="http://en.wikipedia.org/wiki/YCbCr">YCbCr</a> color space.

				<pre><code class="python">from cmt.tools import imread, rgb2ycc

img = rgb2ycc(imread('newyork.png'))</code></pre>

				The first channel of the image, <code>img[:, :, 0]</code>, now contains the
				grayscale information, while the other two channels encode the color information.

				To generate data for the two models, we require two types of masks. We create
				these masks by calling <code>generate_masks</code>.

				<pre><code class="python">from cmt.tools import generate_masks

input_mask0, output_mask0 = generate_masks([7, 0, 0], 1)
input_mask1, output_mask1 = generate_masks([5, 7, 7], 1, [1, 0, 0])</code></pre>

				The first call generates the same masks we used in the
				<a href="images.html">other tutorial</a>, that is, an output mask with one active
				pixel and an input mask representing a causal neighborhood which is 7 pixels wide.
				The masks generated by the second call are a little bit more complex. Since the
				second model will have to deal with multiple channels (one luminance channel and two
				color channels), the masks will also have multiple channels.
				The first argument to <code>generate_masks</code> specifies the size of the
				neighborhood for each channel. The third argument can be used to indicate which
				channels are assumed to be given.

				<figure>
					<img src="media/multichannel_neighborhood.png" alt="Multi-channel neighborhood" width=188 height=60>
					<figcaption>Visualization of the multi-channel mask.</figcaption>
				</figure>

				Since the second model assumes that the luminance information is given, the neighborhood in
				that channel no longer needs to be restricted to a causal neighborhood but can be
				square. Using these masks, we can now train the two models.

				<pre><code class="python">model0, pre0 = train_model(img[:, :, 0], input_mask0, output_mask0)
model1, pre1 = train_model(img,          input_mask1, output_mask1)</code></pre>

				Note that we the first model is only trained on the grayscale portion of the
				image.<br>
				<br>

				<h2 id="sampling">Synthesizing images</h2>
				Generating new images is done in two steps. First, we synthesize a grayscale image.
				Second, we generate the missing color information conditioned on the grayscale
				information.

				<pre><code class="python">from cmt.tools import sample_image

img_sample = img.copy()

# sample luminance
img_sample[:, :, 0] = sample_image(
	img_sample[:, :, 0], model0, input_mask0, output_mask0, pre0)

# sample color
img_sample = sample_image(
	img_sample, model1, input_mask1, output_mask1, pre1)</code></pre>

				First, the boundaries of the sample are initialized. The first call to
				<code>sample_image</code> replaces the grayscale information by sampling from <code>model0</code>.
				The second call to <code>sample_image</code> then replaces the color
				information while using the grayscale information.<br>
				<br>
				Finally, we convert the image back to RGB and save it.
				<pre><code>from cmt.tools import ycc2rgb, imwrite

img_sample = ycc2rgb(img_sample)
imwrite('newyork_sample.png', img_sample, vmin=0, vmax=255)</code></pre>

				<figure>
					<img src="media/newyork_sample.png" alt="New York Sample">
					<figcaption>A sample generated by the two-layer image model.</figcaption>
				</figure>

				The complete example can be found here: <a href="color_images.py">color_images.py</a>.
		</article>
	</body>
</html>
